#!/usr/bin/env python3
"""
Self-Evolution: æ•°æ®åˆ†æå’Œä¼˜åŒ–è„šæœ¬

åˆ†æ skill æ‰§è¡Œæ•°æ®ï¼Œç”Ÿæˆè´¨é‡æŠ¥å‘Šï¼Œå‘ç°æ¨¡å¼ï¼Œä¼˜åŒ–æƒé‡
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import List, Dict, Any, Tuple
import re

# å°è¯•å¯¼å…¥ç§‘å­¦è®¡ç®—åº“
try:
    import numpy as np
    from scipy.stats import pearsonr
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    print("è­¦å‘Š: æœªå®‰è£… scipyï¼Œéƒ¨åˆ†ç»Ÿè®¡åŠŸèƒ½å°†ä¸å¯ç”¨")


class SelfEvolutionAnalyzer:
    """Self-Evolution åˆ†æå™¨"""

    def __init__(self, data_dir: str = None):
        if data_dir is None:
            home = os.path.expanduser("~")
            data_dir = os.path.join(home, ".claude/skills/self-evolution/data")

        self.data_dir = Path(data_dir)
        self.executions_dir = self.data_dir / "executions"
        self.patterns_dir = self.data_dir / "patterns"
        self.weights_dir = self.data_dir / "weights"
        self.reports_dir = self.data_dir / ".." / "reports"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for dir_path in [self.patterns_dir, self.weights_dir, self.reports_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

    def load_executions(self, days: int = 30) -> List[Dict[str, Any]]:
        """åŠ è½½æœ€è¿‘ N å¤©çš„æ‰§è¡Œæ•°æ®"""
        executions = []
        cutoff_date = datetime.now() - timedelta(days=days)

        # éå†æ‰€æœ‰æœˆä»½ç›®å½•
        if not self.executions_dir.exists():
            print(f"è­¦å‘Š: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.executions_dir}")
            return executions

        for month_dir in sorted(self.executions_dir.iterdir()):
            if not month_dir.is_dir() or month_dir.name == '.':
                continue

            # åŠ è½½è¯¥æœˆçš„æ‰€æœ‰æ‰§è¡Œè®°å½•
            for exec_file in month_dir.glob("sess_*.json"):
                try:
                    with open(exec_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # æ£€æŸ¥æ—¥æœŸ
                    exec_date = datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
                    if exec_date >= cutoff_date:
                        executions.append(data)
                except Exception as e:
                    print(f"è­¦å‘Š: æ— æ³•åŠ è½½ {exec_file}: {e}")

        print(f"å·²åŠ è½½ {len(executions)} æ¡æ‰§è¡Œè®°å½•")
        return executions

    def calculate_quality_scores(self, executions: List[Dict]) -> List[Dict]:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        scored = []

        for exec_data in executions:
            scores = {
                'completeness': self._score_completeness(exec_data),
                'consistency': self._score_consistency(exec_data),
                'professionalism': self._score_professionalism(exec_data),
                'performance': self._score_performance(exec_data),
                'maintainability': self._score_maintainability(exec_data)
            }

            # åŠ æƒå¹³å‡
            weights = {
                'completeness': 0.25,
                'consistency': 0.20,
                'professionalism': 0.25,
                'performance': 0.15,
                'maintainability': 0.15
            }

            total_score = sum(scores[k] * weights[k] for k in scores)

            exec_data['quality_score'] = total_score
            exec_data['quality_breakdown'] = scores
            exec_data['quality_grade'] = self._get_grade(total_score)

            scored.append(exec_data)

        return scored

    def _score_completeness(self, exec_data: Dict) -> float:
        """è¯„åˆ†ï¼šå®Œæ•´æ€§"""
        output = exec_data.get('output', {})
        score = 0.0

        # æœ‰ä»£ç è¡Œ
        if output.get('code_lines', 0) > 0:
            score += 0.3

        # æœ‰ç»„ä»¶
        if output.get('components_count', 0) > 0:
            score += 0.2

        # æœ‰å“åº”å¼è®¾è®¡
        if output.get('has_responsive', False):
            score += 0.25

        # æœ‰æš—è‰²æ¨¡å¼
        if output.get('has_dark_mode', False):
            score += 0.25

        return score

    def _score_consistency(self, exec_data: Dict) -> float:
        """è¯„åˆ†ï¼šä¸€è‡´æ€§"""
        elements = exec_data.get('execution', {}).get('elements_used', {})
        score = 1.0

        # æ£€æŸ¥æ ·å¼ä¸€è‡´æ€§
        styles = elements.get('styles', [])
        if len(styles) > 3:
            score -= 0.2  # æ ·å¼å¤ªå¤šå¯èƒ½ä¸ä¸€è‡´

        # æ£€æŸ¥é¢œè‰²ä½¿ç”¨
        colors = elements.get('colors', [])
        if len(colors) > 8:
            score -= 0.2  # é¢œè‰²å¤ªå¤š

        # æ£€æŸ¥å­—ä½“ä½¿ç”¨
        fonts = elements.get('fonts', [])
        if len(fonts) > 3:
            score -= 0.2  # å­—ä½“å¤ªå¤š

        return max(0.0, score)

    def _score_professionalism(self, exec_data: Dict) -> float:
        """è¯„åˆ†ï¼šä¸“ä¸šæ€§"""
        output = exec_data.get('output', {})
        score = 0.5  # åŸºç¡€åˆ†

        # æœ‰å“åº”å¼è®¾è®¡
        if output.get('has_responsive', False):
            score += 0.25

        # æœ‰æš—è‰²æ¨¡å¼
        if output.get('has_dark_mode', False):
            score += 0.25

        return score

    def _score_performance(self, exec_data: Dict) -> float:
        """è¯„åˆ†ï¼šæ€§èƒ½"""
        duration = exec_data.get('execution', {}).get('duration_ms', 0)

        # æ‰§è¡Œæ—¶é—´è¶ŠçŸ­è¶Šå¥½
        if duration < 1000:
            return 1.0
        elif duration < 2000:
            return 0.8
        elif duration < 3000:
            return 0.6
        elif duration < 5000:
            return 0.4
        else:
            return 0.2

    def _score_maintainability(self, exec_data: Dict) -> float:
        """è¯„åˆ†ï¼šå¯ç»´æŠ¤æ€§"""
        output = exec_data.get('output', {})
        components = output.get('components_count', 0)
        lines = output.get('code_lines', 0)

        if lines == 0:
            return 0.0

        # ç»„ä»¶åŒ–ç¨‹åº¦
        if components > 0:
            ratio = components / (lines / 100)  # æ¯ 100 è¡Œä»£ç çš„ç»„ä»¶æ•°
            if ratio >= 1.0:
                return 1.0
            else:
                return 0.5 + (ratio * 0.5)

        return 0.3  # æ²¡æœ‰ç»„ä»¶åŒ–

    def _get_grade(self, score: float) -> str:
        """è·å–ç­‰çº§"""
        if score >= 0.9:
            return 'A'
        elif score >= 0.8:
            return 'B'
        elif score >= 0.7:
            return 'C'
        elif score >= 0.6:
            return 'D'
        else:
            return 'F'

    def discover_patterns(self, executions: List[Dict]) -> Dict[str, Any]:
        """å‘ç°æ¨¡å¼"""
        patterns = {
            'frequent_combinations': self._find_frequent_combinations(executions),
            'search_sequences': self._analyze_search_sequences(executions),
            'success_patterns': self._identify_success_patterns(executions)
        }

        # ä¿å­˜æ¨¡å¼
        output_file = self.patterns_dir / f"patterns_{datetime.now().strftime('%Y%m%d')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(patterns, f, indent=2, ensure_ascii=False)

        print(f"æ¨¡å¼å·²ä¿å­˜åˆ°: {output_file}")
        return patterns

    def _find_frequent_combinations(self, executions: List[Dict]) -> List[Dict]:
        """æ‰¾å‡ºé¢‘ç¹ç»„åˆ"""
        # æ ·å¼ç»„åˆ
        style_combinations = Counter()
        color_combinations = Counter()

        for exec_data in executions:
            elements = exec_data.get('execution', {}).get('elements_used', {})

            # æ ·å¼ç»„åˆ
            styles = tuple(sorted(elements.get('styles', [])))
            if styles:
                style_combinations[styles] += 1

            # é¢œè‰²ç»„åˆ
            colors = tuple(sorted(elements.get('colors', []))[:5])  # åªå–å‰5ä¸ªé¢œè‰²
            if colors:
                color_combinations[colors] += 1

        # å– Top 10
        return {
            'styles': [
                {'combination': list(combo), 'count': count, 'frequency': count / len(executions)}
                for combo, count in style_combinations.most_common(10)
            ],
            'colors': [
                {'combination': list(combo), 'count': count, 'frequency': count / len(executions)}
                for combo, count in color_combinations.most_common(10)
            ]
        }

    def _analyze_search_sequences(self, executions: List[Dict]) -> List[Dict]:
        """åˆ†ææœç´¢åºåˆ—"""
        sequences = Counter()

        for exec_data in executions:
            searches = exec_data.get('execution', {}).get('searches_performed', [])
            if searches:
                # æå–æœç´¢åŸŸåºåˆ—
                domains = tuple(s.get('domain') for s in searches if s.get('domain'))
                if domains:
                    sequences[domains] += 1

        return [
            {'sequence': list(seq), 'count': count, 'frequency': count / len(executions)}
            for seq, count in sequences.most_common(10)
        ]

    def _identify_success_patterns(self, executions: List[Dict]) -> Dict[str, Any]:
        """è¯†åˆ«æˆåŠŸæ¨¡å¼"""
        # ç­›é€‰é«˜è´¨é‡æ‰§è¡Œ
        high_quality = [e for e in executions if e.get('quality_score', 0) >= 0.85]

        if not high_quality:
            return {'message': 'æ²¡æœ‰è¶³å¤Ÿçš„é«˜è´¨é‡æ‰§è¡Œæ•°æ®'}

        # åˆ†æå…±åŒç‰¹å¾
        common_styles = Counter()
        common_searches = Counter()
        common_stacks = Counter()

        for exec_data in high_quality:
            # æ ·å¼
            styles = exec_data.get('execution', {}).get('elements_used', {}).get('styles', [])
            for style in styles:
                common_styles[style] += 1

            # æœç´¢åºåˆ—
            searches = exec_data.get('execution', {}).get('searches_performed', [])
            for search in searches:
                domain = search.get('domain')
                if domain:
                    common_searches[domain] += 1

            # æŠ€æœ¯æ ˆ
            stack = exec_data.get('trigger', {}).get('context', {}).get('tech_stack')
            if stack:
                common_stacks[stack] += 1

        return {
            'high_quality_count': len(high_quality),
            'common_styles': common_styles.most_common(5),
            'common_searches': common_searches.most_common(5),
            'common_stacks': common_stacks.most_common(3),
            'avg_quality_score': np.mean([e['quality_score'] for e in high_quality]) if HAS_SCIPY else sum(e['quality_score'] for e in high_quality) / len(high_quality)
        }

    def optimize_weights(self, executions: List[Dict]) -> Dict[str, float]:
        """ä¼˜åŒ–å…ƒç´ æƒé‡"""
        # è®¡ç®—æ¯ä¸ªå…ƒç´ çš„ä½¿ç”¨é¢‘ç‡å’Œè´¨é‡ç›¸å…³æ€§
        element_stats = defaultdict(lambda: {'usage': 0, 'quality_sum': 0, 'count': 0})

        for exec_data in executions:
            quality = exec_data.get('quality_score', 0)
            elements = exec_data.get('execution', {}).get('elements_used', {})

            # æ ·å¼
            for style in elements.get('styles', []):
                element_stats[f'style:{style}']['usage'] += 1
                element_stats[f'style:{style}']['quality_sum'] += quality
                element_stats[f'style:{style}']['count'] += 1

            # é¢œè‰²
            for color in elements.get('colors', []):
                element_stats[f'color:{color}']['usage'] += 1
                element_stats[f'color:{color}']['quality_sum'] += quality
                element_stats[f'color:{color}']['count'] += 1

        # è®¡ç®—æƒé‡
        weights = {}
        for element, stats in element_stats.items():
            if stats['count'] > 0:
                avg_quality = stats['quality_sum'] / stats['count']
                usage_score = min(1.0, stats['usage'] / len(executions))

                # ç»¼åˆæƒé‡
                weights[element] = avg_quality * 0.6 + usage_score * 0.4

        # ä¿å­˜æƒé‡
        output_file = self.weights_dir / f"weights_{datetime.now().strftime('%Y%m%d')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(weights, f, indent=2, ensure_ascii=False)

        print(f"æƒé‡å·²ä¿å­˜åˆ°: {output_file}")
        return weights

    def generate_dashboard(self, executions: List[Dict], patterns: Dict, weights: Dict) -> str:
        """ç”Ÿæˆä»ªè¡¨æ¿"""
        # ç»Ÿè®¡æ•°æ®
        total_executions = len(executions)
        avg_quality = np.mean([e.get('quality_score', 0) for e in executions]) if HAS_SCIPY else sum(e.get('quality_score', 0) for e in executions) / len(executions) if executions else 0
        avg_duration = np.mean([e.get('execution', {}).get('duration_ms', 0) for e in executions]) if HAS_SCIPY else sum(e.get('execution', {}).get('duration_ms', 0) for e in executions) / len(executions) if executions else 0

        # æŒ‰ skill åˆ†ç»„
        skill_stats = defaultdict(lambda: {'count': 0, 'quality_sum': 0})
        for exec_data in executions:
            skill = exec_data.get('skill_name', 'unknown')
            skill_stats[skill]['count'] += 1
            skill_stats[skill]['quality_sum'] += exec_data.get('quality_score', 0)

        # ç”Ÿæˆ Markdown
        dashboard = f"""# Self-Evolution Dashboard

**æœ€åæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š æ•´ä½“æ¦‚è§ˆ

### æ ¸å¿ƒæŒ‡æ ‡
- **æ€»æ‰§è¡Œæ¬¡æ•°**: {total_executions}
- **å¹³å‡è´¨é‡åˆ†**: {avg_quality:.3f}
- **å¹³å‡æ‰§è¡Œæ—¶é—´**: {avg_duration:.0f}ms
- **æ—¶é—´èŒƒå›´**: æœ€è¿‘ 30 å¤©

### è´¨é‡åˆ†å¸ƒ
"""

        # è´¨é‡åˆ†å¸ƒ
        grade_dist = Counter(e.get('quality_grade', 'F') for e in executions)
        for grade in ['A', 'B', 'C', 'D', 'F']:
            count = grade_dist.get(grade, 0)
            pct = (count / total_executions * 100) if total_executions > 0 else 0
            dashboard += f"- **{grade}çº§**: {count} ({pct:.1f}%)\n"

        dashboard += "\n---\n\n## ğŸ¯ Skill è¡¨ç°\n\n"

        # Skill ç»Ÿè®¡
        for skill, stats in sorted(skill_stats.items(), key=lambda x: x[1]['count'], reverse=True):
            avg_quality_skill = stats['quality_sum'] / stats['count'] if stats['count'] > 0 else 0
            dashboard += f"### {skill}\n"
            dashboard += f"- æ‰§è¡Œæ¬¡æ•°: {stats['count']}\n"
            dashboard += f"- å¹³å‡è´¨é‡: {avg_quality_skill:.3f}\n\n"

        dashboard += "---\n\n## ğŸ” å‘ç°çš„æ¨¡å¼\n\n"

        # é¢‘ç¹ç»„åˆ
        if 'frequent_combinations' in patterns:
            dashboard += "### é¢‘ç¹ç»„åˆ\n\n"
            dashboard += "**æ ·å¼ç»„åˆ Top 5**:\n"
            for combo in patterns['frequent_combinations'].get('styles', [])[:5]:
                dashboard += f"- {', '.join(combo['combination'])} (ä½¿ç”¨ {combo['count']} æ¬¡)\n"

        # æœç´¢åºåˆ—
        if 'search_sequences' in patterns:
            dashboard += "\n**å¸¸ç”¨æœç´¢åºåˆ—**:\n"
            for seq in patterns['search_sequences'][:5]:
                dashboard += f"- {' â†’ '.join(seq['sequence'])} (ä½¿ç”¨ {seq['count']} æ¬¡)\n"

        dashboard += "\n---\n\n## ğŸ“ˆ ä¼˜åŒ–æƒé‡ Top 10\n\n"

        # Top æƒé‡
        sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10]
        for element, weight in sorted_weights:
            dashboard += f"- `{element}`: {weight:.3f}\n"

        dashboard += "\n---\n\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        suggestions = []
        if avg_quality < 0.8:
            suggestions.append("- æ•´ä½“è´¨é‡åˆ†ä½äº 0.8ï¼Œå»ºè®®é‡ç‚¹æå‡å®Œæ•´æ€§å’Œä¸“ä¸šæ€§")
        if avg_duration > 2000:
            suggestions.append("- å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡ 2ç§’ï¼Œå»ºè®®ä¼˜åŒ–æœç´¢ç­–ç•¥")

        if suggestions:
            dashboard += "\n".join(suggestions)
        else:
            dashboard += "- å½“å‰è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼"

        # ä¿å­˜ä»ªè¡¨æ¿
        output_file = self.reports_dir / "dashboard.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(dashboard)

        print(f"ä»ªè¡¨æ¿å·²ä¿å­˜åˆ°: {output_file}")
        return dashboard


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Self-Evolution Analyzer")
    print("=" * 60)

    analyzer = SelfEvolutionAnalyzer()

    # 1. åŠ è½½æ‰§è¡Œæ•°æ®
    print("\n[1/5] åŠ è½½æ‰§è¡Œæ•°æ®...")
    executions = analyzer.load_executions(days=30)

    if not executions:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æ‰§è¡Œæ•°æ®")
        sys.exit(1)

    # 2. è®¡ç®—è´¨é‡åˆ†æ•°
    print("\n[2/5] è®¡ç®—è´¨é‡åˆ†æ•°...")
    executions = analyzer.calculate_quality_scores(executions)

    # 3. å‘ç°æ¨¡å¼
    print("\n[3/5] å‘ç°æ¨¡å¼...")
    patterns = analyzer.discover_patterns(executions)

    # 4. ä¼˜åŒ–æƒé‡
    print("\n[4/5] ä¼˜åŒ–æƒé‡...")
    weights = analyzer.optimize_weights(executions)

    # 5. ç”Ÿæˆä»ªè¡¨æ¿
    print("\n[5/5] ç”Ÿæˆä»ªè¡¨æ¿...")
    dashboard = analyzer.generate_dashboard(executions, patterns, weights)

    print("\n" + "=" * 60)
    print("åˆ†æå®Œæˆï¼")
    print("=" * 60)
    print(f"\nè¯·æŸ¥çœ‹ä»ªè¡¨æ¿: {analyzer.reports_dir / 'dashboard.md'}")


if __name__ == "__main__":
    main()
